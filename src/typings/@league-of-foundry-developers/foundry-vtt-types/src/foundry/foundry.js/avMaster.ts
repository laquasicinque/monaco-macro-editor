
    export default [
      "@league-of-foundry-developers\\foundry-vtt-types\\src\\foundry\\foundry.js\\avMaster.d.ts",
      "/**\n * The master Audio/Video controller instance.\n * This is available as the singleton game.webrtc\n */declare class AVMaster{constructor();settings:AVSettings;config:AVConfig;/**\n * The Audio/Video client class\n */\nclient:InstanceType<CONFIG['WebRTC']['clientClass']>;/**\n * A flag to track whether the current user is actively broadcasting their microphone.\n * @defaultValue `false`\n */\nbroadcasting:boolean;/**\n * Flag to determine if we are connected to the signalling server or not.\n * This is required for synchronization between connection and reconnection attempts.\n * @defaultValue `false`\n * @internal\n */protected _connected:boolean;/**\n * A flag to track whether the A/V system is currently in the process of reconnecting.\n * This occurs if the connection is lost or interrupted.\n * @defaultValue `false`\n * @internal\n */protected _reconnecting:boolean;/**\n * @defaultValue `{}`\n * @internal\n */protected _speakingData:AVMaster.SpeakingData;/**\n * @defaultValue `{}`\n * @internal\n */protected _pttHandlers:AVMaster.PTTHandlers;/**\n * @defaultValue `0`\n * @internal\n */protected _pttMuteTimeout:number;get mode():AVSettings.VoiceMode;/**\n * Connect to the Audio/Video client.\n * @returns Was the connection attempt successful?\n */\nconnect():Promise<boolean>;/**\n * Disconnect from the Audio/Video client.\n * @returns Whether an existing connection was terminated?\n */\ndisconnect():Promise<boolean>;/**\n * Callback actions to take when the user becomes disconnected from the server.\n */\nreestablish():Promise<void>;/**\n * Initialize the local broadcast state.\n * @internal\n */protected _initialize():void;/**\n * A user can broadcast audio if the AV mode is compatible and if they are allowed to broadcast.\n */\ncanUserBroadcastAudio(userId:string):boolean;/**\n * A user can share audio if they are allowed to broadcast and if they have not muted themselves or been blocked.\n */\ncanUserShareAudio(userId:string):boolean;/**\n * A user can broadcast video if the AV mode is compatible and if they are allowed to broadcast.\n */\ncanUserBroadcastVideo(userId:string):boolean;/**\n * A user can share video if they are allowed to broadcast and if they have not hidden themselves or been blocked.\n */\ncanUserShareVideo(userId:string):boolean;/**\n * Trigger a change in the audio broadcasting state when using a push-to-talk workflow.\n * @param intent - The user's intent to broadcast. Whether an actual broadcast occurs will depend\n *                 on whether or not the user has muted their audio feed.\n */\nbroadcast(intent:boolean):void;/**\n * Set up audio level listeners to handle voice activation detection workflow.\n * @param mode - The currently selected voice broadcasting mode\n * @internal\n */protected _initializeUserVoiceDetection(mode:AVSettings.VoiceMode):void;/**\n * Activate voice detection tracking for a userId on a provided MediaStream.\n * Currently only a MediaStream is supported because MediaStreamTrack processing is not yet supported cross-browser.\n * @param userId - The Foundry User ID whose voice is being processed\n * @param stream - The MediaStream which corresponds to that User\n * @param ms     - A number of milliseconds which represents the voice activation volume interval\n *                 (default: `CONFIG.WebRTC.detectPeerVolumeInterval`)\n */\nactivateVoiceDetection(userId:string,stream:MediaStream,ms?:number):void;/**\n * Actions which the orchestration layer should take when a peer user disconnects from the audio/video service.\n * @param userId - The id of the disconnecting User\n */\ndeactivateVoiceDetection(userId:string):void;/**\n * Periodic notification of user audio level\n *\n * This function uses the audio level (in dB) of each stream it's listening to to determine if a user\n * is speaking or not and notifies the UI of such changes.\n *\n * The User is considered speaking if they are above the decibel threshold in any of the history values.\n * This marks them as speaking as soon as they have a high enough volume, and marks them as not speaking only after\n * they drop below the threshold in all histories (last 4 volumes = for 200 ms).\n *\n * There can be more optimal ways to do this and which uses whether the user was already considered speaking before\n * or not, in order to eliminate short bursts of audio (coughing for example).\n *\n * @param userId  - The user ID of the user whose audio levels are being reported\n * @param dbLevel - The audio level in decibels of the user within the last 50ms\n * @internal\n */protected _onAudioLevel(userId:string,dbLevel:number):void;/**\n * Set up interactivity and handling of push-to-talk broadcasting workflow.\n * @internal\n */protected _initializePushToTalk():void;/**\n * Resets the speaking history of a user\n * If the user was considered speaking, then mark them as not speaking\n * @param userId - The ID of the user\n * @internal\n */protected _resetSpeakingHistory(userId:string):void;/**\n * Handle activation of a push-to-talk key or button.\n * @param event - The original keydown event\n * @internal\n */\n_onPTTStart(event:KeyboardEvent|MouseEvent):void;/**\n * Handle deactivation of a push-to-talk key or button.\n * @param event - The original keyup event\n * @internal\n */\n_onPTTEnd(event:KeyboardEvent|MouseEvent):void;/**\n * Handle matching old and new PTT configurations against the mouse or keyboard event.\n * @param event - The original event\n * @internal\n */\n_isPTTKey(event:KeyboardEvent|MouseEvent):boolean;render():void;/**\n * Render the audio/video streams to the CameraViews UI.\n * Assign each connected user to the correct video frame element.\n */\nonRender():void;/**\n * Respond to changes which occur to AV Settings.\n * Changes are handled in descending order of impact.\n * @param changed - The object of changed AV settings\n */\nonSettingsChanged(changed:DeepPartial<AVSettings.Settings>):void;debug(message:string):void;}declare namespace AVMaster{type SpeakingData=Partial<Record<string,{speaking:boolean;volumeHistories:number[]}>>;type PTTHandler=(event:KeyboardEvent|MouseEvent)=>void;type PTTHandlers=|{}|{mousedown:PTTHandler;mouseup:PTTHandler}|{keydown:PTTHandler;keyup:PTTHandler;};}"
    ]
  